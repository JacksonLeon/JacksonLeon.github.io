<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="default">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">























  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  

  
    
      
    

    
  

  
    
    
    <link rel="stylesheet" href="https://fonts.css.network//css?family=Lato:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Monaco:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext">
  






<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=6.7.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.7.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/icon32.png?v=6.7.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/icon16.png?v=6.7.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.7.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '6.7.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="Pytorch Style GuideTo be translated   This is not an official style guide for PyTorch. This document summarizes best practices from more than a year of experience with deep learning using the PyTorch">
<meta name="keywords" content="Python,Reproduce">
<meta property="og:type" content="article">
<meta property="og:title" content="Pytorch Style Guide">
<meta property="og:url" content="https://jacksonleon.gitee.io/posts/3514606856.html">
<meta property="og:site_name" content="GeekJoe">
<meta property="og:description" content="Pytorch Style GuideTo be translated   This is not an official style guide for PyTorch. This document summarizes best practices from more than a year of experience with deep learning using the PyTorch">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2019-05-01T01:03:11.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Pytorch Style Guide">
<meta name="twitter:description" content="Pytorch Style GuideTo be translated   This is not an official style guide for PyTorch. This document summarizes best practices from more than a year of experience with deep learning using the PyTorch">



  <link rel="alternate" href="/atom.xml" title="GeekJoe" type="application/atom+xml">




  <link rel="canonical" href="https://jacksonleon.gitee.io/posts/3514606856.html">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Pytorch Style Guide | GeekJoe</title>
  




  <script async src="//www.googletagmanager.com/gtag/js?id=UA-133178853-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-133178853-1');
  </script>









  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    <a href="https://github.com/JacksonLeon" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewbox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">GeekJoe</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">步子大了容易扯着蛋</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>About</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>Tags</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-notes">

    
    
    
      
    

    

    <a href="/notes/" rel="section"><i class="menu-item-icon fa fa-fw fa-book"></i> <br>Notes</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-friends">

    
    
    
      
    

    

    <a href="/friends/" rel="section"><i class="menu-item-icon fa fa-fw fa-address-book"></i> <br>Friends</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>Search</a>
        </li>
      
    </ul>
  

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="Searching..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://jacksonleon.gitee.io/posts/3514606856.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Joseph">
      <meta itemprop="description" content="Love what you do, do what you love.">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GeekJoe">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Pytorch Style Guide

              
            
          </h1>
        

        <div class="post-meta">
          
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-05-01 09:03:11" itemprop="dateCreated datePublished" datetime="2019-05-01T09:03:11+08:00">2019-05-01</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a></span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Python/Style-Guide/" itemprop="url" rel="index"><span itemprop="name">Style Guide</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <a href="/posts/3514606856.html#comments" itemprop="discussionUrl">
                  <span class="post-meta-item-text">Comments: </span> <span class="post-comments-count valine-comment-count" data-xid="/posts/3514606856.html" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="post-meta-item-icon">
            <i class="fa fa-eye"></i>
             Views:  
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Symbols count in article: </span>
                
                <span title="Symbols count in article">21k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">19 mins.</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="Pytorch-Style-Guide"><a href="#Pytorch-Style-Guide" class="headerlink" title="Pytorch Style Guide"></a>Pytorch Style Guide</h1><div class="note warning"><p>To be translated</p></div>

<blockquote>
<p>This is not an official style guide for PyTorch. This document summarizes best practices from more than a year of experience with deep learning using the PyTorch framework. Note that the learnings we share come mostly from a research and startup perspective.</p>
<p>This is an open project and other collaborators are highly welcomed to edit and improve the document.</p>
<p>You will find three main parts of this doc. First, a quick recap of best practices in Python, followed by some tips and recommendations using PyTorch. Finally, we share some insights and experiences using other frameworks which helped us generally improve our workflow.</p>
</blockquote>
<a id="more"></a>
<h2 id="We-recommend-using-Python-3-6"><a href="#We-recommend-using-Python-3-6" class="headerlink" title="We recommend using Python 3.6+"></a>We recommend using Python 3.6+</h2><p>From our experience we recommend using Python 3.6+ because of the following features which became very handy for clean and simple code:</p>
<ul>
<li><a href="https://medium.com/@ageitgey/learn-how-to-use-static-type-checking-in-python-3-6-in-10-minutes-12c86d72677b" target="_blank" rel="noopener">Support for typing since Python 3.6.</a></li>
<li><a href="https://realpython.com/python-f-strings/" target="_blank" rel="noopener">Support of f strings since Python 3.6</a></li>
</ul>
<h2 id="Python-Styleguide-recap"><a href="#Python-Styleguide-recap" class="headerlink" title="Python Styleguide recap"></a>Python Styleguide recap</h2><p>We try to follow the Google Styleguide for Python.<br>Please refer to the well-documented  <a href="https://github.com/google/styleguide/blob/gh-pages/pyguide.md" target="_blank" rel="noopener">style guide on python code provided by Google</a>.</p>
<p>We provide here a summary of the most commonly used rules:</p>
<h3 id="Naming-Conventions"><a href="#Naming-Conventions" class="headerlink" title="Naming Conventions"></a>Naming Conventions</h3><p><em>From 3.16.4</em></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Type</th>
<th>Convention</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>Packages &amp; Modules</td>
<td>lower_with_under</td>
<td>from <strong>prefetch_generator</strong> import BackgroundGenerator</td>
</tr>
<tr>
<td>Classes</td>
<td>CapWords</td>
<td>class <strong>DataLoader</strong></td>
</tr>
<tr>
<td>Constants</td>
<td>CAPS_WITH_UNDER</td>
<td><strong>BATCH_SIZE=16</strong></td>
</tr>
<tr>
<td>Instances</td>
<td>lower_with_under</td>
<td><strong>dataset</strong> = Dataset</td>
</tr>
<tr>
<td>Methods &amp; Functions</td>
<td>lower_with_under()</td>
<td>def <strong>visualize_tensor()</strong></td>
</tr>
<tr>
<td>Variables</td>
<td>lower_with_under</td>
<td><strong>background_color=’Blue’</strong></td>
</tr>
</tbody>
</table>
</div>
<h2 id="IDEs"><a href="#IDEs" class="headerlink" title="IDEs"></a>IDEs</h2><h3 id="Code-Editors"><a href="#Code-Editors" class="headerlink" title="Code Editors"></a>Code Editors</h3><p>In general, we recommend the use of an IDE such as visual studio code or PyCharm. Whereas VS Code provides syntax highlighting and autocompletion in a relatively lightweight editor PyCharm has lots of advanced features for working with remote clusters.</p>
<h4 id="Setting-up-PyCharm-to-work-with-a-Remote-Machine"><a href="#Setting-up-PyCharm-to-work-with-a-Remote-Machine" class="headerlink" title="Setting up PyCharm to work with a Remote Machine"></a>Setting up PyCharm to work with a Remote Machine</h4><ol>
<li>Login to your remote machine (AWS, Google etc.)</li>
<li>Create a new folder and a new virtual environment</li>
<li>In Pycharm (professional edition) in the project settings setup a remote interpreter</li>
<li>Configure the remote python interpreter (path to venv on AWS, Google etc.)</li>
<li>Configure the mapping of the code from your local machine to the remote machine</li>
</ol>
<p>If set up properly this allows you to do the following:</p>
<ul>
<li>Code on your local computer (notebook, desktop) wherever you want (offline, online)</li>
<li>Sync local code with your remote machine</li>
<li>Additional packages will be installed automatically on a remote machine</li>
<li>You don’t need any dataset on your local machine</li>
<li>Run the code and debug on the remote machine as if it would be your local machine running the code</li>
</ul>
<h2 id="Jupyter-Notebook-vs-Python-Scripts"><a href="#Jupyter-Notebook-vs-Python-Scripts" class="headerlink" title="Jupyter Notebook vs Python Scripts"></a>Jupyter Notebook vs Python Scripts</h2><p>In general, we recommend to use jupyter notebooks for initial exploration/ playing around with new models and code.<br>Python scripts should be used as soon as you want to train the model on a bigger dataset where also reproducibility is more important.</p>
<p><strong>Our recommended workflow:</strong></p>
<ol>
<li>Start with a jupyter notebook</li>
<li>Explore the data and models</li>
<li>Build your classes/ methods inside cells of the notebook</li>
<li>Move your code to python scripts</li>
<li>Train/ deploy on server</li>
</ol>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>Jupyter Notebook</strong></th>
<th><strong>Python Scripts</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>+ Exploration</td>
<td>+ Running longer jobs without interruption</td>
</tr>
<tr>
<td>+ Debugging</td>
<td>+ Easy to track changes with git</td>
</tr>
<tr>
<td>- Can become a huge file</td>
<td>- Debugging mostly means rerunning the whole script</td>
</tr>
<tr>
<td>- Can be interrupted (don’t use for long training)</td>
<td></td>
</tr>
<tr>
<td>- Prone to errors and become a mess</td>
</tr>
</tbody>
</table>
</div>
<h2 id="Libraries"><a href="#Libraries" class="headerlink" title="Libraries"></a>Libraries</h2><p>Commonly used libraries:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
<th>Used for</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://pytorch.org/" target="_blank" rel="noopener">torch</a></td>
<td>Base Framework for working with neural networks</td>
<td>creating tensors, networks and training them using backprop</td>
</tr>
<tr>
<td><a href="https://pytorch.org/docs/stable/torchvision" target="_blank" rel="noopener">torchvision</a></td>
<td>todo</td>
<td>data preprocessing, augmentation, postprocessing</td>
</tr>
<tr>
<td><a href="https://pillow.readthedocs.io/en/stable/" target="_blank" rel="noopener">Pillow (PIL)</a></td>
<td>Python Imaging Library</td>
<td>Loading images and storing them</td>
</tr>
<tr>
<td><a href="https://www.numpy.org/" target="_blank" rel="noopener">Numpy</a></td>
<td>Package for scientific computing with Python</td>
<td>Data preprocessing &amp; postprocessing</td>
</tr>
<tr>
<td><a href="https://pypi.org/project/prefetch_generator/" target="_blank" rel="noopener">prefetch_generator</a></td>
<td>Library for background processing</td>
<td>Loading next batch in background during computation</td>
</tr>
<tr>
<td><a href="https://github.com/tqdm/tqdm" target="_blank" rel="noopener">tqdm</a></td>
<td>Progress bar</td>
<td>Progress during training of each epoch</td>
</tr>
<tr>
<td><a href="https://github.com/sksq96/pytorch-summary" target="_blank" rel="noopener">torchsummary</a></td>
<td>Keras summary for PyTorch</td>
<td>Displays network, it’s parameters and sizes at each layer</td>
</tr>
<tr>
<td><a href="https://github.com/lanpa/tensorboardX" target="_blank" rel="noopener">tensorboardx</a></td>
<td>Tensorboard without tensorflow</td>
<td>Logging experiments and showing them in tensorboard</td>
</tr>
</tbody>
</table>
</div>
<h2 id="File-Organization"><a href="#File-Organization" class="headerlink" title="File Organization"></a>File Organization</h2><p>Don’t put all layers and models into the same file. A best practice is to separate the final networks into a separate file (<em>networks.py</em>) and keep the layers, losses, and ops in respective files (<em>layers.py</em>, <em>losses.py</em>, <em>ops.py</em>). The finished model (composed of one or multiple networks) should be reference in a file with its name (e.g. <em>yolov3.py</em>, <em>DCGAN.py</em>)</p>
<p>The main routine, respective the train and test scripts should only import from the file having the model’s name.</p>
<h2 id="Building-a-Neural-Network-in-PyTorch"><a href="#Building-a-Neural-Network-in-PyTorch" class="headerlink" title="Building a Neural Network in PyTorch"></a>Building a Neural Network in PyTorch</h2><p>We recommend breaking up the network into its smaller reusable pieces. A network is a <strong>nn.Module</strong> consisting of operations or other <strong>nn.Module</strong>s as building blocks. Loss functions are also <strong>nn.Module</strong> and can, therefore, be directly integrated into the network.</p>
<p>A class inheriting from <strong>nn.Module</strong> must have a <em>forward</em> method implementing the forward pass of the respective layer or operation. </p>
<p>A <strong>nn.module</strong> can be used on input data using <strong>self.net(input)</strong>. This simply uses the <em><strong>call</strong>()</em> method of the object to feed the input through the module.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">output = self.net(input)</span><br></pre></td></tr></table></figure>
<h3 id="A-Simple-Network-in-PyTorch"><a href="#A-Simple-Network-in-PyTorch" class="headerlink" title="A Simple Network in PyTorch"></a>A Simple Network in PyTorch</h3><p>Use the following pattern for simple networks with a single input and single output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConvBlock</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(ConvBlock, self).__init__()</span><br><span class="line">        block = [nn.Conv2d(...)]</span><br><span class="line">        block += [nn.ReLU()]</span><br><span class="line">        block += [nn.BatchNorm2d(...)]</span><br><span class="line">        self.block = nn.Sequential(*block)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.block(x)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleNetwork</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_resnet_blocks=<span class="number">6</span>)</span>:</span></span><br><span class="line">        super(SimpleNetwork, self).__init__()</span><br><span class="line">        <span class="comment"># here we add the individual layers</span></span><br><span class="line">        layers = [ConvBlock(...)]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(num_resnet_blocks):</span><br><span class="line">            layers += [ResBlock(...)]</span><br><span class="line">        self.net = nn.Sequential(*layers)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.net(x)</span><br></pre></td></tr></table></figure></p>
<p>Note the following:</p>
<ul>
<li>We reuse simple, recurrent building blocks such as <em>ConvBlock</em> which consists of the same recurrent pattern of (convolution, activation, normalization) and put them into a separate nn.Module</li>
<li>We build up a list of desired layers and finally turn them into a model using <em>nn.Sequential()</em>. We use the * operator before the list object to unwrap it.</li>
<li>In the forward pass we just run the input through the model</li>
</ul>
<h3 id="A-Network-with-skip-connections-in-PyTorch"><a href="#A-Network-with-skip-connections-in-PyTorch" class="headerlink" title="A Network with skip connections in PyTorch"></a>A Network with skip connections in PyTorch</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResnetBlock</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dim, padding_type, norm_layer, use_dropout, use_bias)</span>:</span></span><br><span class="line">        super(ResnetBlock, self).__init__()</span><br><span class="line">        self.conv_block = self.build_conv_block(...)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_conv_block</span><span class="params">(self, ...)</span>:</span></span><br><span class="line">        conv_block = []</span><br><span class="line"></span><br><span class="line">        conv_block += [nn.Conv2d(...),</span><br><span class="line">                       norm_layer(...),</span><br><span class="line">                       nn.ReLU()]</span><br><span class="line">        <span class="keyword">if</span> use_dropout:</span><br><span class="line">            conv_block += [nn.Dropout(...)]</span><br><span class="line">            </span><br><span class="line">        conv_block += [nn.Conv2d(...),</span><br><span class="line">                       norm_layer(...)]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*conv_block)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        out = x + self.conv_block(x)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<p>Here the skip connection of a <em>ResNet block</em> has been implemented directly in the forward pass. PyTorch allows for dynamic operations during the forward pass. </p>
<h3 id="A-Network-with-multiple-outputs-in-PyTorch"><a href="#A-Network-with-multiple-outputs-in-PyTorch" class="headerlink" title="A Network with multiple outputs in PyTorch"></a>A Network with multiple outputs in PyTorch</h3><p>For a network requiring multiple outputs, such as building a perceptual loss using a pretrained VGG network we use the following pattern:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Vgg19</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, requires_grad=False)</span>:</span></span><br><span class="line">    super(Vgg19, self).__init__()</span><br><span class="line">    vgg_pretrained_features = models.vgg19(pretrained=<span class="literal">True</span>).features</span><br><span class="line">    self.slice1 = torch.nn.Sequential()</span><br><span class="line">    self.slice2 = torch.nn.Sequential()</span><br><span class="line">    self.slice3 = torch.nn.Sequential()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">7</span>):</span><br><span class="line">        self.slice1.add_module(str(x), vgg_pretrained_features[x])</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">7</span>, <span class="number">21</span>):</span><br><span class="line">        self.slice2.add_module(str(x), vgg_pretrained_features[x])</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">21</span>, <span class="number">30</span>):</span><br><span class="line">        self.slice3.add_module(str(x), vgg_pretrained_features[x])</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> requires_grad:</span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> self.parameters():</span><br><span class="line">            param.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">    h_relu1 = self.slice1(x)</span><br><span class="line">    h_relu2 = self.slice2(h_relu1)        </span><br><span class="line">    h_relu3 = self.slice3(h_relu2)        </span><br><span class="line">    out = [h_relu1, h_relu2, h_relu3]</span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure></p>
<p>Note here the following:</p>
<ul>
<li>We use a pretrained model provided by <em>torchvision</em>.</li>
<li>We split up the network into three slices. Each slice consists of layers from the pretrained model.</li>
<li>We <em>freeze</em> the network by setting <em>requires_grad = False</em></li>
<li>We return a list with the three outputs of our slices</li>
</ul>
<h2 id="Custom-Loss"><a href="#Custom-Loss" class="headerlink" title="Custom Loss"></a>Custom Loss</h2><p>Even if PyTorch already has a lot of of standard loss function it might be necessary sometimes to create your own loss function. For this, create a separate file <code>losses.py</code> and extend the <code>nn.Module</code> class to create your custom loss function:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomLoss</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(CustomLoss,self).__init__()</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x,y)</span>:</span></span><br><span class="line">        loss = torch.mean((x - y)**<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>
<h2 id="Recommended-code-structure-for-training-your-model"><a href="#Recommended-code-structure-for-training-your-model" class="headerlink" title="Recommended code structure for training your model"></a>Recommended code structure for training your model</h2><p>Note that we used the following patterns:</p>
<ul>
<li>We use <em>BackgroundGenerator</em> from <em>prefetch_generator</em> to load next batches in background</li>
<li>We use tqdm to monitor training progress and show the <em>compute efficiency</em>. This helps us find bottlenecks in our data loading pipeline.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import statements</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> data</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># set flags / seeds</span></span><br><span class="line">torch.backends.cudnn.benchmark = <span class="literal">True</span></span><br><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line">torch.manual_seed(<span class="number">1</span>)</span><br><span class="line">torch.cuda.manual_seed(<span class="number">1</span>)</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start with main code</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># argparse for additional flags for experiment</span></span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">"Train a network for ..."</span>)</span><br><span class="line">    ...</span><br><span class="line">    opt = parser.parse_args() </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># add code for datasets (we always use train and validation/ test set)</span></span><br><span class="line">    data_transforms = transforms.Compose([</span><br><span class="line">        transforms.Resize((opt.img_size, opt.img_size)),</span><br><span class="line">        transforms.RandomHorizontalFlip(),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))</span><br><span class="line">    ])</span><br><span class="line">    </span><br><span class="line">    train_dataset = datasets.ImageFolder(</span><br><span class="line">        root=os.path.join(opt.path_to_data, <span class="string">"train"</span>),</span><br><span class="line">        transform=data_transforms)</span><br><span class="line">    train_data_loader = data.DataLoader(train_dataset, ...)</span><br><span class="line">    </span><br><span class="line">    test_dataset = datasets.ImageFolder(</span><br><span class="line">        root=os.path.join(opt.path_to_data, <span class="string">"test"</span>),</span><br><span class="line">        transform=data_transforms)</span><br><span class="line">    test_data_loader = data.DataLoader(test_dataset ...)</span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># instantiate network (which has been imported from *networks.py*)</span></span><br><span class="line">    net = MyNetwork(...)</span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># create losses (criterion in pytorch)</span></span><br><span class="line">    criterion_L1 = torch.nn.L1Loss()</span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># if running on GPU and we want to use cuda move model there</span></span><br><span class="line">    use_cuda = torch.cuda.is_available()</span><br><span class="line">    <span class="keyword">if</span> use_cuda:</span><br><span class="line">        net = net.cuda()</span><br><span class="line">        ...</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># create optimizers</span></span><br><span class="line">    optim = torch.optim.Adam(net.parameters(), lr=opt.lr)</span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># load checkpoint if needed/ wanted</span></span><br><span class="line">    start_n_iter = <span class="number">0</span></span><br><span class="line">    start_epoch = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> opt.resume:</span><br><span class="line">        ckpt = load_checkpoint(opt.path_to_checkpoint) <span class="comment"># custom method for loading last checkpoint</span></span><br><span class="line">        net.load_state_dict(ckpt[<span class="string">'net'</span>])</span><br><span class="line">        start_epoch = ckpt[<span class="string">'epoch'</span>]</span><br><span class="line">        start_n_iter = ckpt[<span class="string">'n_iter'</span>]</span><br><span class="line">        optim.load_state_dict(ckpt[<span class="string">'optim'</span>])</span><br><span class="line">        print(<span class="string">"last checkpoint restored"</span>)</span><br><span class="line">        ...</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># if we want to run experiment on multiple GPUs we move the models there</span></span><br><span class="line">    net = torch.nn.DataParallel(net)</span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># typically we use tensorboardX to keep track of experiments</span></span><br><span class="line">    writer = SummaryWriter(...)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># now we start the main loop</span></span><br><span class="line">    n_iter = start_n_iter</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(start_epoch, opt.epochs):</span><br><span class="line">        <span class="comment"># set models to train mode</span></span><br><span class="line">        net.train()</span><br><span class="line">        ...</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># use prefetch_generator and tqdm for iterating through data</span></span><br><span class="line">        pbar = tqdm(enumerate(BackgroundGenerator(train_data_loader, ...)),</span><br><span class="line">                    total=len(train_data_loader))</span><br><span class="line">        start_time = time.time()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># for loop going through dataset</span></span><br><span class="line">        <span class="keyword">for</span> i, data <span class="keyword">in</span> pbar:</span><br><span class="line">            <span class="comment"># data preparation</span></span><br><span class="line">            img, label = data</span><br><span class="line">            <span class="keyword">if</span> use_cuda:</span><br><span class="line">                img = img.cuda()</span><br><span class="line">                label = label.cuda()</span><br><span class="line">            ...</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># It's very good practice to keep track of preparation time and computation time using tqdm to find any issues in your dataloader</span></span><br><span class="line">            prepare_time = start_time-time.time()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># forward and backward pass</span></span><br><span class="line">            optim.zero_grad()</span><br><span class="line">            ...</span><br><span class="line">            loss.backward()</span><br><span class="line">            optim.step()</span><br><span class="line">            ...</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># udpate tensorboardX</span></span><br><span class="line">            writer.add_scalar(..., n_iter)</span><br><span class="line">            ...</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># compute computation time and *compute_efficiency*</span></span><br><span class="line">            process_time = start_time-time.time()-prepare_time</span><br><span class="line">            pbar.set_description(<span class="string">"Compute efficiency: &#123;:.2f&#125;, epoch: &#123;&#125;/&#123;&#125;:"</span>.format(</span><br><span class="line">                process_time/(process_time+prepare_time), epoch, opt.epochs))</span><br><span class="line">            start_time = time.time()</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># maybe do a test pass every x epochs</span></span><br><span class="line">        <span class="keyword">if</span> epoch % x == x<span class="number">-1</span>:</span><br><span class="line">            <span class="comment"># bring models to evaluation mode</span></span><br><span class="line">            net.eval()</span><br><span class="line">            ...</span><br><span class="line">            <span class="comment">#do some tests</span></span><br><span class="line">            pbar = tqdm(enumerate(BackgroundGenerator(test_data_loader, ...)),</span><br><span class="line">                    total=len(test_data_loader)) </span><br><span class="line">            <span class="keyword">for</span> i, data <span class="keyword">in</span> pbar:</span><br><span class="line">                ...</span><br><span class="line">                </span><br><span class="line">            <span class="comment"># save checkpoint if needed</span></span><br><span class="line">            ...</span><br></pre></td></tr></table></figure>
<h2 id="Training-on-Multiple-GPUs-in-PyTorch"><a href="#Training-on-Multiple-GPUs-in-PyTorch" class="headerlink" title="Training on Multiple GPUs in PyTorch"></a>Training on Multiple GPUs in PyTorch</h2><p>There are two distinct patterns in PyTorch to use multiple GPUs for training.<br>From our experience both patterns are valid. The first one results however in nicer and less code. The second one seems to have a slight performance advantage due to less communication between the GPUs. <a href="https://discuss.pytorch.org/t/how-to-best-use-dataparallel-with-multiple-models/39289" target="_blank" rel="noopener">I asked a question in the official PyTorch forum about the two approaches here</a></p>
<h3 id="Split-up-the-batch-input-of-each-network"><a href="#Split-up-the-batch-input-of-each-network" class="headerlink" title="Split up the batch input of each network"></a>Split up the batch input of each network</h3><p>The most common one is to simply split up the batches of all <em>networks</em> to the individual GPUs. </p>
<blockquote>
<p>A model running on 1 GPU with batch size 64 would, therefore, run on 2 GPUs with each a batch size of 32. This can be done automatically by wrapping the model by <strong>nn.DataParallel(model)</strong>.</p>
</blockquote>
<h3 id="Pack-all-networks-in-a-super-network-and-split-up-input-batch"><a href="#Pack-all-networks-in-a-super-network-and-split-up-input-batch" class="headerlink" title="Pack all networks in a super network and split up input batch"></a>Pack all networks in a <em>super</em> network and split up input batch</h3><p>This pattern is less commonly used. A repository implemnting this approach is shown here in the <a href="https://github.com/NVIDIA/pix2pixHD" target="_blank" rel="noopener">pix2pixHD implementation by Nvidia</a></p>
<h2 id="Do’s-and-Don’t’s"><a href="#Do’s-and-Don’t’s" class="headerlink" title="Do’s and Don’t’s"></a>Do’s and Don’t’s</h2><h3 id="Avoid-Numpy-Code-in-the-forward-method-of-a-nn-Module"><a href="#Avoid-Numpy-Code-in-the-forward-method-of-a-nn-Module" class="headerlink" title="Avoid Numpy Code in the forward method of a nn.Module"></a>Avoid Numpy Code in the forward method of a nn.Module</h3><p>Numpy runs on the CPU and is slower than torch code. Since torch has been developed with being similar to numpy in mind most numpy functions are supported by PyTorch already.</p>
<h3 id="Separate-the-DataLoader-from-the-main-Code"><a href="#Separate-the-DataLoader-from-the-main-Code" class="headerlink" title="Separate the DataLoader from the main Code"></a>Separate the DataLoader from the main Code</h3><p>The data loading pipeline should be independent of your main training code. PyTorch uses background workers for loading the data more efficiently and without disturbing the main training process.</p>
<h3 id="Don’t-log-results-in-every-step"><a href="#Don’t-log-results-in-every-step" class="headerlink" title="Don’t log results in every step"></a>Don’t log results in every step</h3><p>Typically we train our models for thousands of steps. Therefore, it is enough to log loss and other results every n’th step to reduce the overhead. Especially, saving intermediary results as images can be costly during training.</p>
<h3 id="Use-Command-line-Arguments"><a href="#Use-Command-line-Arguments" class="headerlink" title="Use Command-line Arguments"></a>Use Command-line Arguments</h3><p>It’s very handy to use command-line arguments to set parameters during code execution (<em>batch size</em>, <em>learning rate</em>, etc). An easy way to keep track of the arguments for an experiment is by just printing the dictionary received from <em>parse_args</em>:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="comment"># saves arguments to config.txt file</span></span><br><span class="line">opt = parser.parse_args()</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"config.txt"</span>, <span class="string">"w"</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(opt.__str__())</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<h3 id="Use-detach-to-free-tensors-from-the-graph-if-possible"><a href="#Use-detach-to-free-tensors-from-the-graph-if-possible" class="headerlink" title="Use .detach() to free tensors from the graph if possible"></a>Use <strong>.detach()</strong> to free tensors from the graph if possible</h3><p>PyTorch keeps track of of all operations involving tensors for automatic differentiation. Use <strong>.detach()</strong> to prevent recording of unnecessary operations.</p>
<h3 id="Use-item-for-printing-scalar-tensors"><a href="#Use-item-for-printing-scalar-tensors" class="headerlink" title="Use .item() for printing scalar tensors"></a>Use <strong>.item()</strong> for printing scalar tensors</h3><p>You can print variables directly, however it’s recommended to use <strong>variable.detach()</strong> or <strong>variable.item()</strong>. In earlier PyTorch versions &lt; 0.4 you have to use <strong>.data</strong> to access the tensor of a variable.</p>
<h3 id="Use-the-call-method-instead-of-forward-on-a-nn-Module"><a href="#Use-the-call-method-instead-of-forward-on-a-nn-Module" class="headerlink" title="Use the call method instead of forward on a nn.Module"></a>Use the call method instead of forward on a <strong>nn.Module</strong></h3><p>The two ways are not identical as pointed out in one of the issues <a href="https://github.com/IgorSusmelj/pytorch-styleguide/issues/3" target="_blank" rel="noopener">here</a>:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">output = self.net.forward(input)</span><br><span class="line"><span class="comment"># they are not equal!</span></span><br><span class="line">output = self.net(input)</span><br></pre></td></tr></table></figure></p>
<h2 id="FAQ"><a href="#FAQ" class="headerlink" title="FAQ"></a>FAQ</h2><ol>
<li><p>How to keep my experiments reproducible?</p>
<blockquote>
<p>We recommend setting the following seeds at the beginning of your code:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line">torch.manual_seed(<span class="number">1</span>)</span><br><span class="line">torch.cuda.manual_seed(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>How to improve training and inference speed further?</p>
<blockquote>
<p>On Nvidia GPUs you can add the following line at the beginning of our code. This will allow the cuda backend to optimize your graph during its first execution. However, be aware that if you change the network input/output tensor size the graph will be optimized each time a change occurs. This can lead to very slow runtime and out of memory errors. Only set this flag if your input and output have always the same shape. Usually, this results in an improvement of about 20%.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.backends.cudnn.benchmark = <span class="literal">True</span></span><br></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>What is a good value for compute efficiency using your tqdm + prefetch_generator pattern?</p>
<blockquote>
<p>It depends on the machine used, the preprocessing pipeline and the network size. Running on a SSD on a 1080Ti GPU we see a compute efficiency of almost 1.0 which is an ideal scenario. If shallow (small) networks or a slow harddisk is used the number may drop to around 0.1-0.2 depending on your setup.</p>
</blockquote>
</li>
<li><p>How can I have a batch size &gt; 1 even though I don’t have enough memory?</p>
<blockquote>
<p>In PyTorch we can implement very easily virtual batch sizes. We just prevent the optimizer from making an update of the parameters and sum up the gradients for <em>batch_size</em> cycles.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="comment"># in the main loop</span></span><br><span class="line">out = net(input)</span><br><span class="line">loss = criterion(out, label)</span><br><span class="line"><span class="comment"># we just call backward to sum up gradients but don't perform step here</span></span><br><span class="line">loss.backward() </span><br><span class="line">total_loss += loss.item() / batch_size</span><br><span class="line"><span class="keyword">if</span> n_iter % batch_size == batch_size<span class="number">-1</span>:</span><br><span class="line">    <span class="comment"># here we perform out optimization step using a virtual batch size</span></span><br><span class="line">    optim.step()</span><br><span class="line">    optim.zero_grad()</span><br><span class="line">    print(<span class="string">'Total loss: '</span>, total_loss)</span><br><span class="line">    total_loss = <span class="number">0.0</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>How can I adjust the learning rate during training?</p>
<blockquote>
<p>We can access the learning rate directly using the instantiated optimizer as shown here:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="keyword">for</span> param_group <span class="keyword">in</span> optim.param_groups:</span><br><span class="line">    old_lr = param_group[<span class="string">'lr'</span>]</span><br><span class="line">    new_lr = old_lr * <span class="number">0.1</span></span><br><span class="line">    param_group[<span class="string">'lr'</span>] = new_lr</span><br><span class="line">    print(<span class="string">'Updated lr from &#123;&#125; to &#123;&#125;'</span>.format(old_lr, new_lr))</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>How to use a pretrained model as a loss (non backprop) during training</p>
<blockquote>
<p>If you want to use a pretrained model such as VGG to compute a loss but not train it (e.g. Perceptual loss in style-transfer/ GANs/ Auto-encoder) you can use the following pattern:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="comment"># instantiate the model</span></span><br><span class="line">pretrained_VGG = VGG19(...)</span><br><span class="line"></span><br><span class="line"><span class="comment"># disable gradients (prevent training)</span></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> pretrained_VGG.parameters():  <span class="comment"># reset requires_grad</span></span><br><span class="line">    p.requires_grad = <span class="literal">False</span></span><br><span class="line">...</span><br><span class="line"><span class="comment"># you don't have to use the no_grad() namespace but can just run the model</span></span><br><span class="line"><span class="comment"># no gradients will be computed for the VGG model</span></span><br><span class="line">out_real = pretrained_VGG(input_a)</span><br><span class="line">out_fake = pretrained_VGG(input_b)</span><br><span class="line">loss = any_criterion(out_real, out_fake)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>Why do we use <em>.train()</em> and <em>.eval()</em> in PyTorch?</p>
<blockquote>
<p>Those methods are used to set layers such as <strong>BatchNorm2d</strong> or <strong>Dropout2d</strong> from training to inference mode. Every module which inherits from <strong>nn.Module</strong> has an attribute called <em>isTraining</em>. <strong>.eval()</strong> and <strong>.train()</strong> just simply sets this attribute to True/ False. For more information of how this method is implemented please have a look at <a href="https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html" target="_blank" rel="noopener">the module code in PyTorch</a></p>
</blockquote>
</li>
<li><p>My model uses lots of memory during Inference/ How to run a model properly for inference in PyTorch?</p>
<blockquote>
<p>Make sure that no gradients get computed and stored during your code execution. You can simply use the following pattern to assure that:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="comment"># run model here</span></span><br><span class="line">    out_tensor = net(in_tensor)</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>How to fine-tune a pretrained model?</p>
<blockquote>
<p>In PyTorch you can freeze layers. This will prevent them from being updated during an optimization step.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># you can freeze whole modules using</span></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> pretrained_VGG.parameters():  <span class="comment"># reset requires_grad</span></span><br><span class="line">    p.requires_grad = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>When to use <strong>Variable(…)</strong>?</p>
<blockquote>
<p>Since PyTorch 0.4 <strong>Variable* and </strong>Tensor<strong> have been merged. We don’t have to explicitly create a </strong>Variable** object anymore.</p>
</blockquote>
</li>
<li>Is PyTorch on C++ faster then using Python?<blockquote>
<p>C++ version is about 10% faster</p>
</blockquote>
</li>
<li>Can TorchScript / JIT speed up my code?<blockquote>
<p>Todo…</p>
</blockquote>
</li>
<li>Is PyTorch code using <strong>cudnn.benchmark=True</strong> faster?<blockquote>
<p>From our experience you can gain about 20% speed-up. But the first time you run your model it takes quite some time to<br>build the optimized graph. In some cases (loops in forward pass, no fixed input shape, if/else in forward, etc.) this flag might<br>result in <em>out of memory</em> or other errors.</p>
</blockquote>
</li>
<li>How to use multiple GPUs for training?<blockquote>
<p>Todo…</p>
</blockquote>
</li>
<li>How does <strong>.detach()</strong> work in PyTorch?</li>
</ol>
<blockquote>
<p>If frees a tensor from a computation graph. A nice illustration is shown <a href="http://www.bnikolic.co.uk/blog/pytorch-detach.html" target="_blank" rel="noopener">here</a></p>
</blockquote>

      
    </div>

    
    <div>
      
        
<div class="my_post_copyright">
  <script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>
  
  <!-- JS库 sweetalert 可修改路径 -->
  <script src="https://cdn.bootcss.com/jquery/2.0.0/jquery.min.js"></script>
  <script src="https://unpkg.com/sweetalert/dist/sweetalert.min.js"></script>
  <p><span>本文标题:</span><a href="/posts/3514606856.html">Pytorch Style Guide</a></p>
  <p><span>文章作者:</span><a href="/" title="访问 Joseph 的个人博客">Joseph</a></p>
  <p><span>发布时间:</span>2019年05月01日 - 09:05</p>
  <p><span>最后更新:</span>2019年05月01日 - 09:05</p>
  <p><span>原始链接:</span><a href="/posts/3514606856.html" title="Pytorch Style Guide">https://jacksonleon.gitee.io/posts/3514606856.html</a>
    <span class="copy-path" title="点击复制文章链接"><i class="fa fa-clipboard" data-clipboard-text="https://jacksonleon.gitee.io/posts/3514606856.html" aria-label="复制成功！"></i></span>
  </p>
  <p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">署名-非商业性使用-禁止演绎 4.0 国际</a> 转载请保留原文链接及作者。</p>  
</div>
<script> 
    var clipboard = new Clipboard('.fa-clipboard');
    $(".fa-clipboard").click(function(){
      clipboard.on('success', function(){
        swal({   
          title: "",   
          text: '复制成功',
          icon: "success", 
          showConfirmButton: true
          });
    });
    });  
</script>

      
    </div>
    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Python/" rel="tag"><i class="fa fa-tag"></i> Python</a>
          
            <a href="/tags/Reproduce/" rel="tag"><i class="fa fa-tag"></i> Reproduce</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/posts/1145527125.html" rel="prev" title="Markdown 图床更改及博客推送">
                <i class="fa fa-chevron-left"></i> Markdown 图床更改及博客推送
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/posts/1894126926.html" rel="next" title="Google Python Style Guide">
                Google Python Style Guide <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
            <a href="/">
              <img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="Joseph">
            </a>
            
              <p class="site-author-name" itemprop="name">Joseph</p>
              <p class="site-description motion-element" itemprop="description">Love what you do, do what you love.</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">65</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">43</span>
                    <span class="site-state-item-name">categories</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">43</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/JacksonLeon" title="GitHub &rarr; https://github.com/JacksonLeon" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:pumbjackson@gmail.com" title="E-Mail &rarr; mailto:pumbjackson@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            </div>
          

          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Recommend
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://jacksonleon.github.io/posts/3890174064.html" title="https://jacksonleon.github.io/posts/3890174064.html" rel="noopener" target="_blank">Git Note</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://jacksonleon.github.io/posts/1999510617.html" title="https://jacksonleon.github.io/posts/1999510617.html" rel="noopener" target="_blank">Python Note</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://jacksonleon.github.io/posts/3307335557.html" title="https://jacksonleon.github.io/posts/3307335557.html" rel="noopener" target="_blank">Blog With Hexo</a>
                  </li>
                
              </ul>
            <div id="days"></div>
<script>
function show_date_time(){
window.setTimeout("show_date_time()", 1000);
BirthDay=new Date("01/01/2018 00:00:00");
today=new Date();
timeold=(today.getTime()-BirthDay.getTime());
sectimeold=timeold/1000
secondsold=Math.floor(sectimeold);
msPerDay=24*60*60*1000
e_daysold=timeold/msPerDay
daysold=Math.floor(e_daysold);
e_hrsold=(e_daysold-daysold)*24;
hrsold=setzero(Math.floor(e_hrsold));
e_minsold=(e_hrsold-hrsold)*60;
minsold=setzero(Math.floor((e_hrsold-hrsold)*60));
seconds=setzero(Math.floor((e_minsold-minsold)*60));
document.getElementById('days').innerHTML="已运行 "+daysold+" 天 "+hrsold+" 小时 "+minsold+" 分 "+seconds+" 秒";
}
function setzero(i){
if (i<10)
{i="0" + i};
return i;
}
show_date_time();
</script>
            </div>
          

          
            
          
        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Pytorch-Style-Guide"><span class="nav-number">1.</span> <span class="nav-text">Pytorch Style Guide</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#We-recommend-using-Python-3-6"><span class="nav-number">1.1.</span> <span class="nav-text">We recommend using Python 3.6+</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Python-Styleguide-recap"><span class="nav-number">1.2.</span> <span class="nav-text">Python Styleguide recap</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Naming-Conventions"><span class="nav-number">1.2.1.</span> <span class="nav-text">Naming Conventions</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#IDEs"><span class="nav-number">1.3.</span> <span class="nav-text">IDEs</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Code-Editors"><span class="nav-number">1.3.1.</span> <span class="nav-text">Code Editors</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Setting-up-PyCharm-to-work-with-a-Remote-Machine"><span class="nav-number">1.3.1.1.</span> <span class="nav-text">Setting up PyCharm to work with a Remote Machine</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Jupyter-Notebook-vs-Python-Scripts"><span class="nav-number">1.4.</span> <span class="nav-text">Jupyter Notebook vs Python Scripts</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Libraries"><span class="nav-number">1.5.</span> <span class="nav-text">Libraries</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#File-Organization"><span class="nav-number">1.6.</span> <span class="nav-text">File Organization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Building-a-Neural-Network-in-PyTorch"><span class="nav-number">1.7.</span> <span class="nav-text">Building a Neural Network in PyTorch</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#A-Simple-Network-in-PyTorch"><span class="nav-number">1.7.1.</span> <span class="nav-text">A Simple Network in PyTorch</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#A-Network-with-skip-connections-in-PyTorch"><span class="nav-number">1.7.2.</span> <span class="nav-text">A Network with skip connections in PyTorch</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#A-Network-with-multiple-outputs-in-PyTorch"><span class="nav-number">1.7.3.</span> <span class="nav-text">A Network with multiple outputs in PyTorch</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Custom-Loss"><span class="nav-number">1.8.</span> <span class="nav-text">Custom Loss</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Recommended-code-structure-for-training-your-model"><span class="nav-number">1.9.</span> <span class="nav-text">Recommended code structure for training your model</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Training-on-Multiple-GPUs-in-PyTorch"><span class="nav-number">1.10.</span> <span class="nav-text">Training on Multiple GPUs in PyTorch</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Split-up-the-batch-input-of-each-network"><span class="nav-number">1.10.1.</span> <span class="nav-text">Split up the batch input of each network</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pack-all-networks-in-a-super-network-and-split-up-input-batch"><span class="nav-number">1.10.2.</span> <span class="nav-text">Pack all networks in a super network and split up input batch</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Do’s-and-Don’t’s"><span class="nav-number">1.11.</span> <span class="nav-text">Do’s and Don’t’s</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Avoid-Numpy-Code-in-the-forward-method-of-a-nn-Module"><span class="nav-number">1.11.1.</span> <span class="nav-text">Avoid Numpy Code in the forward method of a nn.Module</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Separate-the-DataLoader-from-the-main-Code"><span class="nav-number">1.11.2.</span> <span class="nav-text">Separate the DataLoader from the main Code</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Don’t-log-results-in-every-step"><span class="nav-number">1.11.3.</span> <span class="nav-text">Don’t log results in every step</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Use-Command-line-Arguments"><span class="nav-number">1.11.4.</span> <span class="nav-text">Use Command-line Arguments</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Use-detach-to-free-tensors-from-the-graph-if-possible"><span class="nav-number">1.11.5.</span> <span class="nav-text">Use .detach() to free tensors from the graph if possible</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Use-item-for-printing-scalar-tensors"><span class="nav-number">1.11.6.</span> <span class="nav-text">Use .item() for printing scalar tensors</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Use-the-call-method-instead-of-forward-on-a-nn-Module"><span class="nav-number">1.11.7.</span> <span class="nav-text">Use the call method instead of forward on a nn.Module</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FAQ"><span class="nav-number">1.12.</span> <span class="nav-text">FAQ</span></a></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="heart">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Joseph</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Symbols count total: </span>
    
    <span title="Symbols count total">399k</span>
  

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    
      <span class="post-meta-item-text">Reading time total &asymp;</span>
    
    <span title="Reading time total">6:03</span>
  
</div>









        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="Total Visitors">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="Total Views">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>














  
    
    
  
  <script color="0,0,255" opacity="0.5" zindex="-1" count="99" src="/lib/canvas-nest/canvas-nest.min.js"></script>













  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=6.7.0"></script>

  <script src="/js/src/motion.js?v=6.7.0"></script>



  
  


  <script src="/js/src/affix.js?v=6.7.0"></script>

  <script src="/js/src/schemes/pisces.js?v=6.7.0"></script>



  
  <script src="/js/src/scrollspy.js?v=6.7.0"></script>
<script src="/js/src/post-details.js?v=6.7.0"></script>



  


  <script src="/js/src/bootstrap.js?v=6.7.0"></script>



  
  

<script src="//cdn1.lncld.net/static/js/3.11.1/av-min.js"></script>



<script src="//unpkg.com/valine/dist/Valine.min.js"></script>

<script>
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: true,
    appId: 'O9aoAtFO2Mk0VrPqbyHMHwah-gzGzoHsz',
    appKey: '1bF6m0SPiN3sk9TaGxPELdjY',
    placeholder: 'Just go go',
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: false
  });
</script>




  


  

  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  

  
  

  
  

  


  

  

  

  

  

  

  
  <style>
    .copy-btn {
      display: inline-block;
      padding: 6px 12px;
      font-size: 13px;
      font-weight: 700;
      line-height: 20px;
      color: #333;
      white-space: nowrap;
      vertical-align: middle;
      cursor: pointer;
      background-color: #eee;
      background-image: linear-gradient(#fcfcfc, #eee);
      border: 1px solid #d5d5d5;
      border-radius: 3px;
      user-select: none;
      outline: 0;
    }

    .highlight-wrap .copy-btn {
      transition: opacity .3s ease-in-out;
      opacity: 0;
      padding: 2px 6px;
      position: absolute;
      right: 4px;
      top: 8px;
    }

    .highlight-wrap:hover .copy-btn,
    .highlight-wrap .copy-btn:focus {
      opacity: 1
    }

    .highlight-wrap {
      position: relative;
    }
  </style>
  <script>
    $('.highlight').each(function(i, e) {
      var $wrap = $('<div>').addClass('highlight-wrap');
      $(e).after($wrap);
      $wrap.append($('<button>').addClass('copy-btn').append('Copy').on('click', function(e) {
        var code = $(this).parent().find('.code').find('.line').map(function(i, e) {
          return $(e).text();
        }).toArray().join('\n');
        var ta = document.createElement('textarea');
        var range = document.createRange(); //For Chrome
        var sel = window.getSelection(); //For Chrome
        var yPosition = window.pageYOffset || document.documentElement.scrollTop;
        ta.style.top = yPosition + 'px'; //Prevent page scroll
        ta.style.position = 'absolute';
        ta.style.opacity = '0';
        ta.value = code;
        ta.textContent = code; //For FireFox
        ta.contentEditable = true;
        ta.readOnly = false;
        document.body.appendChild(ta);
        range.selectNode(ta);
        sel.removeAllRanges();
        sel.addRange(range);
        ta.setSelectionRange(0, code.length);
        var result = document.execCommand('copy');
        
          if (result) $(this).text('Copied');
          else $(this).text('Copy failed');
        
        ta.blur(); //For iOS
        $(this).blur();
      })).on('mouseleave', function(e) {
        var $b = $(this).find('.copy-btn');
        setTimeout(function() {
          $b.text('Copy');
        }, 300);
      }).append(e);
    })
  </script>


  

</body>
</html>
<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/clicklove.js"></script>