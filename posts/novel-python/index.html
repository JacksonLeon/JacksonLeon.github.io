<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="generator" content="Hugo 0.82.0" />

  <title> 使用Python爬虫爬取网络小说 |  imlauzh</title>
  <meta name="description" content="A website built by Joseph Lau and host by Github pages.">
  <link rel="stylesheet" href="/blog/css/index.css">
  <link rel="stylesheet" href="/blog/css/classes.css">
  <link rel="canonical" href="/blog/posts/novel-python/">
  <link rel="alternate" type="application/rss+xml" href="" title="imlauzh">
  
  
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css" rel="stylesheet">
  <link 
    rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" 
    integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" 
    crossorigin="anonymous">
  </link>
  <script 
    defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" 
    integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" 
    crossorigin="anonymous">
  </script>
  <script 
    defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" 
    integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" 
    crossorigin="anonymous" 
    onload="renderMathInElement(document.body);">
  </script>
</head>

<body>
  <header class="menus">
  

  <nav >
    
    <a href="/blog/"> Home</a>
    
    <a href="/blog/categories/"> Categories</a>
    
    <a href="/blog/tags/"> Tags</a>
    
    <a href="/blog/about/"> About</a>
    
    <a href="/blog/index.xml"> Subscribe</a>
    
  </nav>

  <nav class="fontawesome">
    
    <a href="https://github.com/imlauzh" target="_blank">
        <i title="GitHub" class="fab fa-github"></i>
    </a>
    
    
    <a href="/blog/index.xml" target="_blank">
        <i title="RSS" class="fas fa-rss"></i>
    </a>
    
  </nav>
  
  
  <div class="hidden description">A website built by Joseph Lau and host by Github pages.</div>
  
</header>

<article id="article">
  <header>
  

    <h1 style="text-align: center;" >使用Python爬虫爬取网络小说</h1>
    <div class="post-meta">
    
      <time datetime="2018-04-12T10:57:34Z">April 12, 2018</time> &nbsp; 
    

     &nbsp;

    
    
      <i class="far fa-eye"></i>
      <span id="/blog/posts/novel-python/" class="leancloud_visitors" data-flag-title="使用Python爬虫爬取网络小说">
          <span class="leancloud-visitors-count">  </span>
      </span> &nbsp;
    
    

    
      <i class="far fa-clock"></i>
      
      
      

      
        2 min
      
      6 s
      &nbsp;
    
    </div>
  </header>

  <ul>
<li>小说网址</li>
</ul>
<blockquote>
<p><a href="https://www.uxiaoshuo.com/">https://www.uxiaoshuo.com/</a></p>
</blockquote>
<ul>
<li>使用<a href="https://www.uxiaoshuo.com/124/124629/">绝色妖娆：鬼医至尊</a>为例</li>
</ul>
<p>下面是程序代码</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#coding:utf-8</span>

<span style="color:#f92672">import</span>  requests
<span style="color:#f92672">import</span> threading
<span style="color:#f92672">from</span> bs4 <span style="color:#f92672">import</span> BeautifulSoup
<span style="color:#f92672">import</span> re
<span style="color:#f92672">import</span> os
<span style="color:#f92672">import</span> time
<span style="color:#f92672">import</span> sys
<span style="color:#f92672">import</span> threading

req_header<span style="color:#f92672">=</span>{
<span style="color:#e6db74">&#39;Accept&#39;</span>:<span style="color:#e6db74">&#39;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8&#39;</span>,
<span style="color:#e6db74">&#39;Accept-Encoding&#39;</span>:<span style="color:#e6db74">&#39;gzip, deflate, br&#39;</span>,
<span style="color:#e6db74">&#39;Accept-Language&#39;</span>:<span style="color:#e6db74">&#39;zh-CN,zh;q=0.9&#39;</span>,
<span style="color:#e6db74">&#39;Cookie&#39;</span>:<span style="color:#e6db74">&#39;UM_distinctid=162afbabff819e-03f2f082776e95-b34356b-1fa400-162afbabff9294; CNZZDATA1259019190=1993576859-1523364262-https%253A</span><span style="color:#e6db74">%252F%252F</span><span style="color:#e6db74">www.baidu.com</span><span style="color:#e6db74">%252F</span><span style="color:#e6db74">%7C1523364262; bookid=124629; chapterid=6510968; chaptername=</span><span style="color:#e6db74">%25u</span><span style="color:#e6db74">7B2C1</span><span style="color:#e6db74">%25u</span><span style="color:#e6db74">7AE0</span><span style="color:#e6db74">%2520%</span><span style="color:#e6db74">25u6797</span><span style="color:#e6db74">%25u</span><span style="color:#e6db74">4E2D</span><span style="color:#e6db74">%25u</span><span style="color:#e6db74">9634</span><span style="color:#e6db74">%25u</span><span style="color:#e6db74">8C0B&#39;</span>,
<span style="color:#e6db74">&#39;Host&#39;</span>:<span style="color:#e6db74">&#39;www.uxiaoshuo.com&#39;</span>,
<span style="color:#e6db74">&#39;Proxy-Connection&#39;</span>:<span style="color:#e6db74">&#39;keep-alive&#39;</span>,
<span style="color:#e6db74">&#39;Referer&#39;</span>:<span style="color:#e6db74">&#39;https://www.uxiaoshuo.com/&#39;</span>,
<span style="color:#e6db74">&#39;Upgrade-Insecure-Requests&#39;</span>:<span style="color:#e6db74">&#39;1&#39;</span>,
<span style="color:#e6db74">&#39;User-Agent&#39;</span>:<span style="color:#e6db74">&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36&#39;</span>
}

req_url_base<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;http://www.uxiaoshuo.com&#39;</span>                <span style="color:#75715e">#小说主地址</span>

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_txt</span>(txt_id):
    txt<span style="color:#f92672">=</span>{}
    _req_url<span style="color:#f92672">=</span>[]
    txt[<span style="color:#e6db74">&#39;title&#39;</span>]<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;&#39;</span>
    txt[<span style="color:#e6db74">&#39;id&#39;</span>]<span style="color:#f92672">=</span>str(txt_id)                                   <span style="color:#75715e">#小说编号</span>
    _req_url<span style="color:#f92672">=</span>txt[<span style="color:#e6db74">&#39;id&#39;</span>]<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39;.&#39;</span>)
    req_url<span style="color:#f92672">=</span>req_url_base<span style="color:#f92672">+</span> txt[<span style="color:#e6db74">&#39;id&#39;</span>]                         <span style="color:#75715e">#根据小说编号获取小说URL</span>
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;小说编号：&#34;</span><span style="color:#f92672">+</span>req_url)
    <span style="color:#66d9ef">try</span>:
        res<span style="color:#f92672">=</span>requests<span style="color:#f92672">.</span>get(req_url, params<span style="color:#f92672">=</span>req_header)             <span style="color:#75715e">#获取小说第一章界面</span>
        soups<span style="color:#f92672">=</span>BeautifulSoup(res<span style="color:#f92672">.</span>text,<span style="color:#e6db74">&#34;html.parser&#34;</span>)             <span style="color:#75715e">#soup转化</span>
        <span style="color:#75715e">#获取小说题目</span>
        txt[<span style="color:#e6db74">&#39;title&#39;</span>]<span style="color:#f92672">=</span>soups<span style="color:#f92672">.</span>select(<span style="color:#e6db74">&#39;#webhtml .box_con .con_top a&#39;</span>)[<span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>text
        <span style="color:#75715e">#打开小说文件写入小说相关信息</span>
        fo <span style="color:#f92672">=</span> open(<span style="color:#e6db74">&#39;{0}.txt&#39;</span><span style="color:#f92672">.</span>format(txt[<span style="color:#e6db74">&#39;title&#39;</span>]), <span style="color:#e6db74">&#34;ab+&#34;</span>)
        <span style="color:#75715e">#循环写入章节内容</span>
        <span style="color:#66d9ef">while</span> <span style="color:#ae81ff">1</span>:
            <span style="color:#66d9ef">if</span> _req_url[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]<span style="color:#f92672">!=</span><span style="color:#e6db74">&#39;html&#39;</span>:
                <span style="color:#66d9ef">print</span>(txt[<span style="color:#e6db74">&#39;title&#39;</span>]<span style="color:#f92672">+</span><span style="color:#e6db74">&#34;全部下载成功！&#34;</span>)
                <span style="color:#66d9ef">break</span>
            txt[<span style="color:#e6db74">&#39;c_title&#39;</span>]<span style="color:#f92672">=</span>soups<span style="color:#f92672">.</span>select(<span style="color:#e6db74">&#39;#webhtml .box_con .zhangjieming h1&#39;</span>)[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>text     <span style="color:#75715e">##章节名称</span>
            txt[<span style="color:#e6db74">&#39;content&#39;</span>]<span style="color:#f92672">=</span>soups<span style="color:#f92672">.</span>select(<span style="color:#e6db74">&#39;#webhtml .box_con .zhangjieTXT&#39;</span>)[<span style="color:#ae81ff">0</span>]
            <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> txt[<span style="color:#e6db74">&#39;content&#39;</span>]<span style="color:#f92672">.</span>select(<span style="color:#e6db74">&#34;script&#34;</span>):           <span style="color:#75715e">#去除无用内容</span>
                i<span style="color:#f92672">.</span>decompose()
            <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> txt[<span style="color:#e6db74">&#39;content&#39;</span>]<span style="color:#f92672">.</span>select(<span style="color:#e6db74">&#34;div&#34;</span>):
                i<span style="color:#f92672">.</span>decompose()
            txt[<span style="color:#e6db74">&#39;content&#39;</span>]<span style="color:#f92672">=</span>re<span style="color:#f92672">.</span>sub( <span style="color:#e6db74">&#39;\s+&#39;</span>, <span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\r\n\t</span><span style="color:#e6db74">&#39;</span>, txt[<span style="color:#e6db74">&#39;content&#39;</span>]<span style="color:#f92672">.</span>text)<span style="color:#f92672">.</span>strip(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\r\n</span><span style="color:#e6db74">&#39;</span>)
            <span style="color:#75715e">#以二进制写入章节题目</span>
            fo<span style="color:#f92672">.</span>write((<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">+</span>txt[<span style="color:#e6db74">&#39;c_title&#39;</span>]<span style="color:#f92672">+</span><span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\r\n</span><span style="color:#e6db74">&#39;</span>)<span style="color:#f92672">.</span>encode(<span style="color:#e6db74">&#39;UTF-8&#39;</span>))
            <span style="color:#75715e">#以二进制写入章节内容</span>
            fo<span style="color:#f92672">.</span>write((<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">+</span>txt[<span style="color:#e6db74">&#39;content&#39;</span>]<span style="color:#f92672">+</span><span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>)<span style="color:#f92672">.</span>encode(<span style="color:#e6db74">&#39;UTF-8&#39;</span>))
            <span style="color:#66d9ef">print</span>(txt[<span style="color:#e6db74">&#39;c_title&#39;</span>])
            <span style="color:#75715e"># print(&#39;章节名:&#39;+txt[&#39;c_title&#39;])</span>
            <span style="color:#75715e"># print(&#34;章节内容：\n&#34;+txt[&#39;content&#39;])</span>
            req_url<span style="color:#f92672">=</span>soups<span style="color:#f92672">.</span>select(<span style="color:#e6db74">&#39;#webhtml .zhangjieming .bottem1 a&#39;</span>)[<span style="color:#ae81ff">3</span>][<span style="color:#e6db74">&#39;href&#39;</span>]
            _req_url<span style="color:#f92672">=</span>req_url<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39;.&#39;</span>)
            req_url<span style="color:#f92672">=</span>req_url_base<span style="color:#f92672">+</span>req_url
            res<span style="color:#f92672">=</span>requests<span style="color:#f92672">.</span>get(req_url, params<span style="color:#f92672">=</span>req_header)             <span style="color:#75715e">#获取下一章界面</span>
            soups<span style="color:#f92672">=</span>BeautifulSoup(res<span style="color:#f92672">.</span>text,<span style="color:#e6db74">&#34;html.parser&#34;</span>)             <span style="color:#75715e">#soup转化</span>
    <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span> <span style="color:#66d9ef">as</span> e:
        <span style="color:#66d9ef">print</span>(e)
    <span style="color:#66d9ef">finally</span>:
        <span style="color:#66d9ef">return</span>

get_txt(<span style="color:#e6db74">&#39;/124/124629/7404934.html&#39;</span>)
get_txt(<span style="color:#e6db74">&#39;/135/135169/7373986.html&#39;</span>)
</code></pre></div><blockquote>
<p>要爬取该网站内的小说，只需要将参数改成自己需要的小说就可以了</p>
</blockquote>

  
  <footer>
    <hr>
    
    <div class="post-tags">
    
      <i class="fas fa-tags"></i>
      
        <a href="/blog/tags/reptile">Reptile</a>
        &nbsp;
      
        <a href="/blog/tags/python">Python</a>
        &nbsp;
      
    
    </div>
  </footer>
  

  


  <div class="comments">



  <div class="comments-item" >
    
    
    
    <div id="vcomments"></div>
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
    <script src='//unpkg.com/valine/dist/Valine.min.js'></script>
    <script type="text/javascript">
      new Valine({
          el: '#vcomments',
          highlight: false,
          lang: "en",
          appId: "O9aoAtFO2Mk0VrPqbyHMHwah-gzGzoHsz",
          appKey: "1bF6m0SPiN3sk9TaGxPELdjY",
          placeholder: "Say Something......",
          requiredFields: ["nick","mail"],
          avatar: "robohash",
          visitor:  true ,
          recordIP: true
      });
    </script>
    <script>
      if(window.location.hash){
          var checkExist = setInterval(function() {
             if ($(window.location.hash).length) {
                $('html, body, article').animate({scrollTop: $(window.location.hash).offset().top-90}, 1000);
                clearInterval(checkExist);
             }
          }, 100);
      }
    </script>
  </div>

</div>

</article>



  
  
  
</body>
<div class="foot">
  
  
    &copy; 2017 - 2021 &#183; 
    <a href="/">imlauzh</a> · Theme <a href="https://github.com/RainerChiang/simpleness">Simpleness</a> Powered by <a href="https://gohugo.io/">Hugo</a> &#183;
    <a href="#"><i class="fas fa-chevron-up"></i></a>
  

  
</div>

<script src="/blog/js/lazyload.min.js"></script>
<script>
  var lazyImage = new LazyLoad({
    container: document.getElementById('article')
  });
</script>


</html>
