<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>论文笔记 - Learning from Context or Names? An Empirical Study on Neural Relation Extraction | 早柳</title>
<meta name="keywords" content="Relation Extraction, NLP" />
<meta name="description" content="背景   什么类型的信息在影响着RE模型区分句子包含什么关系？
 句子中两个重要的信息：上下文和实体mention 对于人类直觉来说，句子的上下文对我们影响更大 之后的方法倾向于编码成分布式表示并进行匹配从而实现预测关系分类 影响程度：  两种信息都很重要 现有的RE数据集在训练过程中会从实体提及中泄露一部分信息，提高了性能   以后的方向：更好地理解句子的上下文以及利用实体提及。防止只是简单的记忆（拟合） 本文使用wikidata去聚类相同的关系实例，学习去分辨句子之间的相似度和属于不同的关系    模型
 CNN  Nguyen and Grishman (2015) Zhang et al. (2017)   BERT  BERT for RE following Baldini Soares et al. (2019)   MTB  Baldini Soares et al. (2019) pre-train a BERTbase version of MTB    CP    实验
  Context&#43;Mention (C&#43;M) Context&#43;Type (C&#43;T)  We replace entity mentions with their types provided in TACRED.">
<meta name="author" content="iiuzh">
<link rel="canonical" href="/blog/posts/context-or-name/" />
<link crossorigin="anonymous" href="/blog/assets/css/stylesheet.min.2aaaa791ce70d6126b4ab0ef3803317a119450a70e1349a1648eb79ff2187457.css" integrity="sha256-Kqqnkc5w1hJrSrDvOAMxehGUUKcOE0mhZI63n/IYdFc=" rel="preload stylesheet" as="style">
<link rel="icon" href="/blog/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="/blog/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/blog/favicon-32x32.png">
<link rel="apple-touch-icon" href="/blog/apple-touch-icon.png">
<link rel="mask-icon" href="/blog/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.82.0" />


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
<meta property="og:title" content="论文笔记 - Learning from Context or Names? An Empirical Study on Neural Relation Extraction" />
<meta property="og:description" content="背景   什么类型的信息在影响着RE模型区分句子包含什么关系？
 句子中两个重要的信息：上下文和实体mention 对于人类直觉来说，句子的上下文对我们影响更大 之后的方法倾向于编码成分布式表示并进行匹配从而实现预测关系分类 影响程度：  两种信息都很重要 现有的RE数据集在训练过程中会从实体提及中泄露一部分信息，提高了性能   以后的方向：更好地理解句子的上下文以及利用实体提及。防止只是简单的记忆（拟合） 本文使用wikidata去聚类相同的关系实例，学习去分辨句子之间的相似度和属于不同的关系    模型
 CNN  Nguyen and Grishman (2015) Zhang et al. (2017)   BERT  BERT for RE following Baldini Soares et al. (2019)   MTB  Baldini Soares et al. (2019) pre-train a BERTbase version of MTB    CP    实验
  Context&#43;Mention (C&#43;M) Context&#43;Type (C&#43;T)  We replace entity mentions with their types provided in TACRED." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/blog/posts/context-or-name/" />
<meta property="og:image" content="/blog/posts/context-or-name/%3Cimage%20path/url%3E" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-11-04T15:56:37&#43;08:00" />
<meta property="article:modified_time" content="2020-11-04T15:56:37&#43;08:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="/blog/posts/context-or-name/%3Cimage%20path/url%3E" />
<meta name="twitter:title" content="论文笔记 - Learning from Context or Names? An Empirical Study on Neural Relation Extraction"/>
<meta name="twitter:description" content="背景   什么类型的信息在影响着RE模型区分句子包含什么关系？
 句子中两个重要的信息：上下文和实体mention 对于人类直觉来说，句子的上下文对我们影响更大 之后的方法倾向于编码成分布式表示并进行匹配从而实现预测关系分类 影响程度：  两种信息都很重要 现有的RE数据集在训练过程中会从实体提及中泄露一部分信息，提高了性能   以后的方向：更好地理解句子的上下文以及利用实体提及。防止只是简单的记忆（拟合） 本文使用wikidata去聚类相同的关系实例，学习去分辨句子之间的相似度和属于不同的关系    模型
 CNN  Nguyen and Grishman (2015) Zhang et al. (2017)   BERT  BERT for RE following Baldini Soares et al. (2019)   MTB  Baldini Soares et al. (2019) pre-train a BERTbase version of MTB    CP    实验
  Context&#43;Mention (C&#43;M) Context&#43;Type (C&#43;T)  We replace entity mentions with their types provided in TACRED."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "/blog/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "论文笔记 - Learning from Context or Names? An Empirical Study on Neural Relation Extraction",
      "item": "/blog/posts/context-or-name/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "论文笔记 - Learning from Context or Names? An Empirical Study on Neural Relation Extraction",
  "name": "论文笔记 - Learning from Context or Names? An Empirical Study on Neural Relation Extraction",
  "description": "背景   什么类型的信息在影响着RE模型区分句子包含什么关系？\n 句子中两个重要的信息：上下文和实体mention 对于人类直觉来说，句子的上下文对我们影响更大 之后的方法倾向于编码成分布式表示并进行匹配从而实现预测关系分类 影响程度：  两种信息都很重要 现有的RE数据集在训练过程中会从实体提及中泄露一部分信息，提高了性能   以后的方向：更好地理解句子的上下文以及利用实体提及。防止只是简单的记忆（拟合） 本文使用wikidata去聚类相同的关系实例，学习去分辨句子之间的相似度和属于不同的关系    模型\n CNN  Nguyen and Grishman (2015) Zhang et al. (2017)   BERT  BERT for RE following Baldini Soares et al. (2019)   MTB  Baldini Soares et al. (2019) pre-train a BERTbase version of MTB    CP    实验\n  Context+Mention (C+M) Context+Type (C+T)  We replace entity mentions with their types provided in TACRED.",
  "keywords": [
    "Relation Extraction", "NLP"
  ],
  "articleBody": "背景   什么类型的信息在影响着RE模型区分句子包含什么关系？\n 句子中两个重要的信息：上下文和实体mention 对于人类直觉来说，句子的上下文对我们影响更大 之后的方法倾向于编码成分布式表示并进行匹配从而实现预测关系分类 影响程度：  两种信息都很重要 现有的RE数据集在训练过程中会从实体提及中泄露一部分信息，提高了性能   以后的方向：更好地理解句子的上下文以及利用实体提及。防止只是简单的记忆（拟合） 本文使用wikidata去聚类相同的关系实例，学习去分辨句子之间的相似度和属于不同的关系    模型\n CNN  Nguyen and Grishman (2015) Zhang et al. (2017)   BERT  BERT for RE following Baldini Soares et al. (2019)   MTB  Baldini Soares et al. (2019) pre-train a BERTbase version of MTB    CP    实验\n  Context+Mention (C+M) Context+Type (C+T)  We replace entity mentions with their types provided in TACRED. We use special tokens to represent them: for example, we use [person] and [date] to represent an entity with type person and date respectively. we do not repeat the special tokens for entity-length times to avoid leaking entity length information   Only Context (OnlyC)  we replace all entity mentions with the special tokens [SUBJ] and [OBJ]. In this case, the information source of entity mentions is totally blocked   Only Mention (OnlyM) Only Type (OnlyT)    分析\n 目前的模型对句子的语义信息的理解还不够，仅仅保持在记忆的阶段 模型从实体名称中所利用的大部分信息是type信息 基于实体名称的模型在预测阶段可能会受到训练集的bias，另一方面，单纯的C+T可能无法更好的理解文本 错误分析-onlyC   wrong：可以推测出来但是模型预测错误：almost half no pattern：人类也无法根据上下文推测出句子包含的关系 confusing：句子的意思模糊      Contrastive Pre-training for RE  生成数据   数据需要包含足够的区别，不能仅仅增加实体类型和不同的上下文，也要避免模型记住实体的mention contrastive learning：Hadsell et al., 2006 随机mask实体，70%， 模型的主要目标是，使学习到的具有相同关系的句子的representation相似，而不同关系的句子的representation区分开来 所以存在噪音也是可以接受的   训练  损失函数   其中  h和t是[E1],[E2]\t$ENC_i()$是transformer的encoder输出 Denote the MLM loss as LMLM       实验   在[[Han et al_2018_FewRel]]的基础上对模型进行修改  使用[E1],[E2]作为表示，而不是[CLS] 使用点积，而不是欧几里得距离计算相似度 性能提高“a large margin”   性能  在all C+M,OnlyC and OnlyM都取得了提升     ",
  "wordCount" : "180",
  "inLanguage": "en",
  "image":"/blog/posts/context-or-name/%3Cimage%20path/url%3E","datePublished": "2020-11-04T15:56:37+08:00",
  "dateModified": "2020-11-04T15:56:37+08:00",
  "author":[{
    "@type": "Person",
    "name": "iiuzh"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/blog/posts/context-or-name/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "早柳",
    "logo": {
      "@type": "ImageObject",
      "url": "/blog/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>
<noscript>
    <style type="text/css">
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: #1d1e20;
                --entry: #2e2e33;
                --primary: rgba(255, 255, 255, 0.84);
                --secondary: rgba(255, 255, 255, 0.56);
                --tertiary: rgba(255, 255, 255, 0.16);
                --content: rgba(255, 255, 255, 0.74);
                --hljs-bg: #2e2e33;
                --code-bg: #37383e;
                --border: #333;
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="/blog" accesskey="h" title="早柳 (Alt + H)">早柳</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu" onscroll="menu_on_scroll()">
            <li>
                <a href="/blog/posts" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="/blog/notes" title="Notes">
                    <span>Notes</span>
                </a>
            </li>
            <li>
                <a href="/blog/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="/blog/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="/blog/archives" title="Timeline">
                    <span>Timeline</span>
                </a>
            </li>
            <li>
                <a href="/blog/friends/" title="Friends">
                    <span>Friends</span>
                </a>
            </li>
            <li>
                <a href="/blog/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="/blog">Home</a>&nbsp;»&nbsp;<a href="/blog/posts/">Posts</a></div>
    <h1 class="post-title">
      论文笔记 - Learning from Context or Names? An Empirical Study on Neural Relation Extraction
    </h1>
    <div class="post-meta">November 4, 2020&nbsp;·&nbsp;1 min&nbsp;·&nbsp;iiuzh
</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <div class="details">Table of Contents</div>
        </summary>
        <div class="inner"><ul>
                <li>
                    <a href="#%e8%83%8c%e6%99%af" aria-label="背景">背景</a></li>
                <li>
                    <a href="#contrastive-pre-training-for-re" aria-label="Contrastive Pre-training for RE">Contrastive Pre-training for RE</a></li>
                <li>
                    <a href="#%e5%ae%9e%e9%aa%8c" aria-label="实验">实验</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="背景">背景<a hidden class="anchor" aria-hidden="true" href="#背景">#</a></h2>
<ul>
<li>
<p>什么类型的信息在影响着RE模型区分句子包含什么关系？</p>
<ul>
<li>句子中两个重要的信息：上下文和实体mention</li>
<li>对于人类直觉来说，句子的上下文对我们影响更大</li>
<li>之后的方法倾向于编码成分布式表示并进行匹配从而实现预测关系分类</li>
<li>影响程度：
<ul>
<li>两种信息都很重要</li>
<li>现有的RE数据集在训练过程中会从实体提及中泄露一部分信息，提高了性能</li>
</ul>
</li>
<li>以后的方向：更好地理解句子的上下文以及利用实体提及。防止只是简单的记忆（拟合）</li>
<li>本文使用wikidata去聚类相同的关系实例，学习去分辨句子之间的相似度和属于不同的关系</li>
</ul>
</li>
<li>
<p>模型</p>
<ul>
<li>CNN
<ul>
<li><a href="https://www.aclweb.org/anthology/W15-1506">Nguyen and Grishman (2015)</a></li>
<li><a href="https://nlp.stanford.edu/pubs/zhang2017tacred.pdf">Zhang et al. (2017)</a></li>
</ul>
</li>
<li>BERT
<ul>
<li>BERT for RE following <a href="https://doi.org/10.18653/v1/P19-1279">Baldini Soares et al. (2019)</a></li>
</ul>
</li>
<li>MTB
<ul>
<li><a href="https://doi.org/10.18653/v1/P19-1279">Baldini Soares et al. (2019)</a></li>
<li>pre-train a BERTbase version of MTB</li>
<li><img loading="lazy" src="https://cdn.jsdelivr.net/gh/imlauzh/img_host@master/BERTbase%20version%20of%20MTB.png" alt=""  />
</li>
</ul>
</li>
<li>CP</li>
</ul>
</li>
<li>
<p>实验</p>
<ul>
<li><img loading="lazy" src="https://cdn.jsdelivr.net/gh/imlauzh/img_host@master/TACRED%20results%20%28micro%20F1%29%20with%20CNN,%20BERTand%20MTB%20on%20different%20settings.png" alt=""  />
</li>
<li>Context+Mention (C+M)</li>
<li>Context+Type (C+T)
<ul>
<li>We replace entity mentions with their types provided in TACRED.</li>
<li>We use special tokens to represent them:</li>
<li>for example, we use [person] and [date] to represent an entity with type person and date respectively.</li>
<li>we do not repeat the special tokens for entity-length times to avoid leaking entity length information</li>
</ul>
</li>
<li>Only Context (OnlyC)
<ul>
<li>we replace all entity mentions with the special tokens [SUBJ] and [OBJ]. In this case, the information source of entity mentions is totally blocked</li>
</ul>
</li>
<li>Only Mention (OnlyM)</li>
<li>Only Type (OnlyT)</li>
</ul>
</li>
<li>
<p>分析</p>
<ul>
<li>目前的模型对句子的语义信息的理解还不够，仅仅保持在记忆的阶段</li>
<li>模型从实体名称中所利用的大部分信息是type信息</li>
<li>基于实体名称的模型在预测阶段可能会受到训练集的bias，另一方面，单纯的C+T可能无法更好的理解文本</li>
<li>错误分析-onlyC
<ul>
<li><img loading="lazy" src="https://cdn.jsdelivr.net/gh/imlauzh/img_host@master/Case%20study%20on%20unique%20wrong%20predictions%20made%20by%20OnlyC.png" alt=""  />
</li>
<li>wrong：可以推测出来但是模型预测错误：almost half</li>
<li>no pattern：人类也无法根据上下文推测出句子包含的关系</li>
<li>confusing：句子的意思模糊</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="contrastive-pre-training-for-re">Contrastive Pre-training for RE<a hidden class="anchor" aria-hidden="true" href="#contrastive-pre-training-for-re">#</a></h2>
<ul>
<li>生成数据
<ul>
<li><img loading="lazy" src="https://cdn.jsdelivr.net/gh/imlauzh/img_host@master/Our%20contrastive%20pre-training%20framework%20for%20RE.png" alt=""  />
</li>
<li>数据需要包含足够的区别，不能仅仅增加实体类型和不同的上下文，也要避免模型记住实体的mention</li>
<li>contrastive learning：<a href="https://www.researchgate.net/profile/Yann_Lecun/publication/4246277_Dimensionality_Reduction_by_Learning_an_Invariant_Mapping/links/00b7d514af9f25ecca000000/Dimensionality-Reduction-by-Learning-an-Invariant-Mapping.pdf">Hadsell et al., 2006</a></li>
<li>随机mask实体，70%，</li>
<li>模型的主要目标是，使学习到的具有相同关系的句子的representation相似，而不同关系的句子的representation区分开来</li>
<li>所以存在噪音也是可以接受的</li>
</ul>
</li>
<li>训练
<ul>
<li>损失函数
<ul>
<li><img loading="lazy" src="https://cdn.jsdelivr.net/gh/imlauzh/img_host@master/training%20objective%20for%20cp%20model.png" alt=""  />
</li>
<li>其中</li>
<li><img loading="lazy" src="https://cdn.jsdelivr.net/gh/imlauzh/img_host@master/relation-aware%20representation%20for%20cp%20model.png" alt=""  />
</li>
<li>h和t是[E1],[E2]	$ENC_i()$是transformer的encoder输出</li>
<li>Denote the MLM loss as LMLM</li>
<li><img loading="lazy" src="https://cdn.jsdelivr.net/gh/imlauzh/img_host@master/training%20loss%20for%20masked%20language%20model.png" alt=""  />
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="实验">实验<a hidden class="anchor" aria-hidden="true" href="#实验">#</a></h2>
<ul>
<li><img loading="lazy" src="https://cdn.jsdelivr.net/gh/imlauzh/img_host@master/Results%20on%20supervised%20RE%20datasets%20TACRED%20%28micro%20F1%29,%20SemEval%20%28micro%20F1%29,%20Wiki80%20%28accuracy%29%20andChemProt%20%28micro%20F1%29.png" alt=""  />
</li>
<li>在[[Han et al_2018_FewRel]]的基础上对模型进行修改
<ul>
<li>使用[E1],[E2]作为表示，而不是[CLS]</li>
<li>使用点积，而不是欧几里得距离计算相似度</li>
<li>性能提高“a large margin”</li>
</ul>
</li>
<li>性能
<ul>
<li>在all C+M,OnlyC and OnlyM都取得了提升</li>
<li><img loading="lazy" src="https://cdn.jsdelivr.net/gh/imlauzh/img_host@master/Accuracy%20on%20FewRel%20dataset%20in%20cp%20model.png" alt=""  />
</li>
</ul>
</li>
</ul>

</div>
  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="/blog/tags/relation-extraction/">Relation Extraction</a></li>
      <li><a href="/blog/tags/nlp/">NLP</a></li>
    </ul>
<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share 论文笔记 - Learning from Context or Names? An Empirical Study on Neural Relation Extraction on twitter"
        href="https://twitter.com/intent/tweet/?text=%e8%ae%ba%e6%96%87%e7%ac%94%e8%ae%b0%20-%20Learning%20from%20Context%20or%20Names%3f%20An%20Empirical%20Study%20on%20Neural%20Relation%20Extraction&amp;url=%2fblog%2fposts%2fcontext-or-name%2f&amp;hashtags=RelationExtraction%2cNLP">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 论文笔记 - Learning from Context or Names? An Empirical Study on Neural Relation Extraction on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fblog%2fposts%2fcontext-or-name%2f&amp;title=%e8%ae%ba%e6%96%87%e7%ac%94%e8%ae%b0%20-%20Learning%20from%20Context%20or%20Names%3f%20An%20Empirical%20Study%20on%20Neural%20Relation%20Extraction&amp;summary=%e8%ae%ba%e6%96%87%e7%ac%94%e8%ae%b0%20-%20Learning%20from%20Context%20or%20Names%3f%20An%20Empirical%20Study%20on%20Neural%20Relation%20Extraction&amp;source=%2fblog%2fposts%2fcontext-or-name%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 论文笔记 - Learning from Context or Names? An Empirical Study on Neural Relation Extraction on reddit"
        href="https://reddit.com/submit?url=%2fblog%2fposts%2fcontext-or-name%2f&title=%e8%ae%ba%e6%96%87%e7%ac%94%e8%ae%b0%20-%20Learning%20from%20Context%20or%20Names%3f%20An%20Empirical%20Study%20on%20Neural%20Relation%20Extraction">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 论文笔记 - Learning from Context or Names? An Empirical Study on Neural Relation Extraction on facebook"
        href="https://facebook.com/sharer/sharer.php?u=%2fblog%2fposts%2fcontext-or-name%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 论文笔记 - Learning from Context or Names? An Empirical Study on Neural Relation Extraction on whatsapp"
        href="https://api.whatsapp.com/send?text=%e8%ae%ba%e6%96%87%e7%ac%94%e8%ae%b0%20-%20Learning%20from%20Context%20or%20Names%3f%20An%20Empirical%20Study%20on%20Neural%20Relation%20Extraction%20-%20%2fblog%2fposts%2fcontext-or-name%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 论文笔记 - Learning from Context or Names? An Empirical Study on Neural Relation Extraction on telegram"
        href="https://telegram.me/share/url?text=%e8%ae%ba%e6%96%87%e7%ac%94%e8%ae%b0%20-%20Learning%20from%20Context%20or%20Names%3f%20An%20Empirical%20Study%20on%20Neural%20Relation%20Extraction&amp;url=%2fblog%2fposts%2fcontext-or-name%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>

  </footer>
</article>
    </main>
    <footer class="footer">
    <span>&copy; 2021 <a href="/blog">早柳</a></span>
    <span>&middot;</span>
    <span>Powered by <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a></span>
    <span>&middot;</span>
    <span>Theme <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a></span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)">
    <button class="top-link" id="top-link" type="button" accesskey="g">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z" />
        </svg>
    </button>
</a>

<script>
    window.onload = function () {
        if (localStorage.getItem("menu-scroll-position")) {
            document.getElementById('menu').scrollLeft = localStorage.getItem("menu-scroll-position");
        }
    }

    function menu_on_scroll() {
        localStorage.setItem("menu-scroll-position", document.getElementById('menu').scrollLeft);
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
