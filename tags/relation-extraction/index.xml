<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Relation Extraction on imlauzh</title>
    <link>/blog/tags/relation-extraction/</link>
    <description>Recent content in Relation Extraction on imlauzh</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>[imlauzh](/) &amp;#183; Theme [Simpleness](https://github.com/RainerChiang/simpleness) Powered by [Hugo](https://gohugo.io/)</copyright>
    <lastBuildDate>Fri, 11 Dec 2020 20:23:04 +0800</lastBuildDate><atom:link href="/blog/tags/relation-extraction/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Chen Et Al__Relabel the Noise</title>
      <link>/blog/posts/chen-et-al_2020_relabel-the-noise/</link>
      <pubDate>Fri, 11 Dec 2020 20:23:04 +0800</pubDate>
      
      <guid>/blog/posts/chen-et-al_2020_relabel-the-noise/</guid>
      <description>问题  协变量偏移，该问题是由受外部知识图约束的带噪声标签的训练集与人工注释的测试集之间的不一致引起的。 作者提出了一种联合提取方法，通过使用一组协作式多智能体(cooperative multiagents)重新标记噪音实例来解决此问题。
  人工标注价格昂贵，所以出现了[[Distant Supervision]]方法，通过将外部的知识图谱对齐到语料库自动生成训练数据，但是会引入噪音标注，降低模型性能。 前人解决办法  概率图模型 注意力机制神经网络 强化学习选择   但是，大部分现存的工作都忽视了标签分布偏移问题 两种标注噪音  False Positive：没有关系的实体对被标记了关系 False Negative：有关系的实体对被忽视或者标记了None  这里的是False Negative还是True Negative？ 这里的False代表的是这条数据存在噪音，怎么判断噪音呢？DS生成的关系与base抽取器抽取出的关系不同，就认定为存在噪音（争议）。 Neg代表的是DS数据集中关系为None，但是抽取出有关系，Pos则相反。     现存的降噪工作基本都是通过对噪音数据分配低权重或者直接舍弃，并没有解决这个问题，将其恢复到正确的标注 并且pipeline模式会产生错误级联，加剧标签分布问题  本文方法 ![](https://cdn.jsdelivr.net/gh/imlauzh/img_host@master/research/(https://cdn.jsdelivr.net/gh/imlauzh/img_host@master/research/Overview%20of%20the%20proposed%20method.pn)
 每一个agent会通过计算连续的confidence score来evaluate实例 confidence score可以用来将噪音训练数据重新分布、调整更新训练loss confidence consensus用来汇合所有agent计算到的一个特征，其实也就是平均 两个任务（实体抽取和关系抽取）之间存在某种联系和相互增强的作用，可以为减少噪音提供一些提示和帮助 -&amp;gt; 联合模型 主要流程  输入：远程监督训练数据$D={s_1,&amp;hellip;,s_n}$，实体抽取器${\theta}_e^{&#39;}$，关系抽取器${\theta}_r^{&#39;}$（都是在D上用预训练模型进行[[Fine Tune|微调]]的） multiagents利用confidence-scored label对训练集D进行重新分布，然后利用修改后的标签重新对${\theta}_e^{&#39;}$和${\theta}_r^{&#39;}$进行训练得到最终的抽取器。   本文为了达到上述的目标，将问题建模成一个mltuiagents强化学习的问题 因为我们没有测试集的gold label的数据，没法判断调整之后的label的正确性，所以使用RL来利用validation set上的性能标准来间接判断好坏 两个抽取器之间通过intermediate agent来交换信息 利用在validation上的性能分数和一致的分数来对agents进行reward 这个方法可以看作是后处理 Confidence Evaluators as Agents  status  entity：现在的句子、抽取结果（类型）、噪音标签类型 relation：句子、抽取类型、噪音标签 复用了base抽取器的句子和type向量，使其轻量化   Actions  利用神经网络去决定当前的句子是pos or neg，并且计算confidence score  pos：根据抽取出来的关系类型 neg：None type   使用[Gated Recurrent Unit]来作为[[Policy Network]]，通过一个[[Sigmoid Function]]来计算概率，其实也就是confidence score，1/0分别对应pos/neg 通过使用多个agents来解决state spaces太大的问题，如何解决的：  目标类型使用agents数量平均分 每个agents只负责一部分 前面提到过不同agents之间交互是通过一个叫做intermediate agents实现的 每个句子对应一个r agent和2个e agents，其他mask掉  这样难道不会有太多的agents么？会不会影响速度       Re-labeling with Confidence Consensus  有点像模型投票 $c = c_{sum}/3$，为什么是3呢，因为前文是1 r+2 e confidence小于0.</description>
    </item>
    
  </channel>
</rss>
